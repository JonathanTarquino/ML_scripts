# -*- coding: utf-8 -*-
"""feature_extract_invent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I7ApJ85qjlitSNb2aSm128iD6cb2MFH-
"""
############################  REQUIREMENTS FOR THIS CODE
# pip install pyradiomics
# pip install mahotas
# pip install pip pyfeats
# pip install medviz

#from radiomics import featureextractor
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from skimage.measure import label, regionprops, regionprops_table
import math
import glob
import skimage
from scipy.signal import convolve2d, medfilt2d, convolve
from scipy.ndimage.filters import generic_filter
from skimage.filters import sobel_h, sobel_v, sobel
from skimage.filters.rank import gradient,mean
from skimage.morphology import erosion,dilation, footprint_rectangle
from skimage.util import img_as_uint, img_as_ubyte
import cv2 as cv
import mahotas
from scipy.stats import kurtosis, skew
from scipy import ndimage as ndi
from skimage import data
from skimage.util import img_as_float
from skimage.filters import gabor_kernel
from pyfeats import lte_measures

from medviz.feats import collage
from medviz.feats.collage.main import Collage, HaralickFeature
print(Collage)

####################################################################################################################

def boundingbox2(vol, mask=[], n=[],slice_opt=None,disp_opt=None):
  min_col = 1000000
  min_row = 1000000
  max_col = 0
  max_row = 0

  # make all zero values in the original volume nonzero

  volcopy = vol

  minval = np.max(vol.ravel())/10000
  vol[vol == 0] = minval

  if len(mask)>1: #use the mask to create a bounding box:
    if np.shape(np.unique(mask))[0]>2:
      print('************ Provided mask is not binary ***************\n' )
      return []

    elif len(np.shape(mask))<3:
      print('Provided binary mask')
      label_img = label(mask)
      regions = skimage.measure.regionprops(label_img)
      for props in regions:
        minr, minc, maxr, maxc = props.bbox
        if min_col>minc:
          min_col=minc

        if min_row>minr:
          min_row=minr


        if max_col<maxc:
          max_col=maxc

        if max_row<maxr:
          max_row=maxr
      croppedV = volcopy[min_row-n:max_row+n,min_col-n:max_col+n]
      croppedM = mask[min_row-n:max_row+n,min_col-n:max_col+n]

    else:
      print('Cropping the image...')
      for sl in range(np.shape(mask)[2]):
        label_img = label(mask[:,:,sl])
        regions = skimage.measure.regionprops(label_img)
        for props in regions:
          minr, minc, maxr, maxc = props.bbox
          if min_col>minc:
            min_col=minc

          if min_row>minr:
            min_row=minr


          if max_col<maxc:
            max_col=maxc

          if max_row<maxr:
            max_row=maxr
        croppedV[:,:,sl] = volcopy[min_row-n:max_row+n,min_col-n:max_col+n]
        croppedM[:,:,sl] = mask[min_row-n:max_row+n,min_col-n:max_col+n]

  else: #use the image volume to create a bounding box:
    print('Cropping the image...')
    ### For testing puprposes
    # print(minval)
    # plt.imshow(vol>minval)
    # plt.show()
    vol_mask = vol>minval
    label_img = label(vol_mask)
    regions = skimage.measure.regionprops(label_img)
    for props in regions:
      minr, minc, maxr, maxc = props.bbox
      if min_col>minc:
        min_col=minc

      if min_row>minr:
        min_row=minr


      if max_col<maxc:
        max_col=maxc

      if max_row<maxr:
        max_row=maxr

    croppedV = volcopy[min_row-n:max_row+n,min_col-n:max_col+n]
    croppedM = mask[min_row-n:max_row+n,min_col-n:max_col+n]
  print('Cropping the image...')
  return croppedV,croppedM

###############################################################################################################

def extract2DFeatIntensities(featVol, mask, vals=1):

  # %INPUTS
  # % featVol = 3-D volume of texture features
  # % mask = 2-D annotation image
  # % vals = vector of mask values to find intensities within

  # % OUTPUT
  # % varargout = cell array(s) of intensities. Number based on length of vals
  #print('\n\tExtracting requested features\n',np.shape(featVol))
  joinFeat = []
  joinFeat = pd.DataFrame(joinFeat)
  if (not featVol.all) or (not mask.all) or (not vals):
        return []

  if len(np.shape(featVol)) > 2:
    print(len(np.shape(mask)))
    if len(np.shape(mask)) < 3:
      print('Generating feature vector(s) for the same mask shaped ',np.shape(joinFeat),type(joinFeat))
      for i in range(np.shape(featVol)[2]): # loop through all features
        f = featVol[:,:,i] #single feature volume
        joinFeat = pd.concat([joinFeat,pd.DataFrame(f[mask==vals].ravel(order='F'))], axis=1)
    else:
      print('Generating feature vector(s) for corresponding masks shaped',np.shape(joinFeat),type(joinFeat))
      for i in range(np.shape(featVol)[2]): # loop through all features
        f = featVol[:,:,i] #single feature volume
        m = mask[:,:,i]
        joinFeat = pd.concat([joinFeat,pd.DataFrame(f[m==vals].ravel(order='F'))], axis=1)


  else:
    print('Extracting single feature matrix')
    f = featVol #single feature volume
    for j in range(vals):# loop through all mask values
      joinFeat = f[mask==vals].ravel(order='F')
  #   print(f,'\n',joinFeat)
  # print(np.shape(joinFeat))
  return joinFeat

def rangefilt(I,window):
  if I.dtype in ['uint8','uint16']:
    kernel= footprint_rectangle((window,window))
    imgOutput = gradient(I,kernel)
    #print('Rangefilt output',imgOutput)
  else:
    Im=I.astype(np.uint8)
    kernel= footprint_rectangle((window,window))
    imgOutput = gradient(Im,kernel)
    #print('Rangefilt output',imgOutput)

  return imgOutput

#####################################################################################################################################

def grayfilts2(img,WindowSize=3):
  print(':::::::::::::::::::::::::')
  # grayFilt = []
  # grayFilt = pd.DataFrame(grayFilt)
  imShape = np.shape(img)
  if len(imShape)>2:
    print('Only 2D images supported, see GRAYFILTS3 otherwise.\n')
    return ()
  else:
    grayFilt = np.zeros((np.shape(img)[0],np.shape(img)[1],4))

    # Calculating Mean image
    print('Calculating Mean Image.\n')
    kernel = np.ones([WindowSize,WindowSize])/(WindowSize*WindowSize)
    filtResult = convolve2d(img, kernel, mode='same')
    grayFilt[:,:,0] = filtResult
    # grayFilt = pd.concat([grayFilt,pd.DataFrame(filtResult)])

    # Calculating Median image
    print('Calculating Median Image.\n')
    filtResult = medfilt2d(img,kernel_size=WindowSize)
    grayFilt[:,:,1] = filtResult
    # grayFilt = pd.concat([grayFilt,pd.DataFrame(filtResult)])

    # Calculating windowed standard deviation filter
    print('Calculating std Image.\n')
    filtResult = generic_filter(img, np.std, size=WindowSize)
    grayFilt[:,:,2] = filtResult
    # grayFilt = pd.concat([grayFilt,pd.DataFrame(filtResult)])

    # Calculating windowed range filter
    print('Calculating Windowed range image.\n')
    filtResult = rangefilt(img, WindowSize)
    grayFilt[:,:,3] = filtResult
    # grayFilt = pd.concat([grayFilt,pd.DataFrame(filtResult)])
    print(np.shape(grayFilt))
  return grayFilt

## -------------------------------------------------------------------------
def sobelxydiag(img):
  sobel = np.array([[0, 1, 2], [-1, 0, 1], [-2, -1, 0]])
  Y = convolve2d(img, sobel, mode='same')
  return Y
## -------------------------------------------------------------------------

def sobelyxdiag(img):
  sobel = np.array([[0, 1, 2], [-1, 0, 1], [-2, -1, 0]])
  sobel = np.fliplr(sobel)
  Y = convolve2d(img, sobel, mode='same')
  return Y

## -------------------------------------------------------------------------

def dx(img):
  Y = np.diff(img,axis=0)
  return Y

## -------------------------------------------------------------------------

def dy(img):
  mask = np.array([[1 ],[-1]])
  Y = convolve(img,mask,'same')
  return Y

## -------------------------------------------------------------------------

def ddiag(img):
  mask = np. array([[-1 ,0],[0,1]])
  Y = convolve2d(img,mask,'same')
  return Y

def gradfilts2(img):
  imSize = np.shape(img)
  if len(imSize)>2:
    print('Error: only 2D images are supported, provided:', imSize)
    return []

  else:
    feat_names = ['Gradient sobelx','Gradient sobely','Gradient sobelxy','Gradient sobelyx','Gradient x','Gradient y','Gradient magnitude','Gradient dx','Gradient dy','Gradient diagonal']

    nfeatures=len(feat_names);
    gradfeats=np.ones([imSize[0],imSize[1], nfeatures]);


    print('Calculating x,y Sobel edge images.\n')
    gradfeats[:,:,0] = sobel_h(img)
    gradfeats[:,:,1] = sobel_v(img)

    print('Calculating diagonal Sobel edge images.\n')
    gradfeats[:,:,2] = sobelxydiag(img)
    gradfeats[:,:,3] = sobelyxdiag(img)

    print('Calculating directional and magnitude gradients.\n')
    gradfeats[:,:,4],gradfeats[:,:,5] = np.gradient(img)

    gradfeats[:,:,6]=np.sqrt(gradfeats[:,:,4]**2 +gradfeats[:,:,5]**2)
    gradfeats[:,:,7]=np.vstack([dx(img),np.zeros(np.shape(img)[1])])
    gradfeats[:,:,8]=dy(img)
    gradfeats[:,:,9]=ddiag(img)

    return gradfeats

########################################################################################################################################

def extractHaralick(img,window,d=1):

  paddedImage = np.zeros((np.shape(img)[0]+(2*window),np.shape(img)[1]+(2*window)))
  print('Padded image shape:',np.shape(img),np.shape(paddedImage))
  HM = np.zeros((np.shape(img)[0],np.shape(img)[1],13))

  if img.dtype in ['uint8','uint16']:
    print('Making a int8 copy of the image')
    paddedImage[0+math.floor(window/2):np.shape(img)[0]+math.floor(window/2),0+math.floor(window/2):np.shape(img)[1]+math.floor(window/2)] = img
    paddedImage=paddedImage.astype(np.uint8)
    print('\n \t using a distance of_:', d)
    for row in range(np.shape(img)[0]):
      for col in range(np.shape(img)[1]):
        #print('rrrrrrrooooooooooowwwwwwwwww........',row,'cooooooooooollllllll',col)
        slidingW = paddedImage[row:row+window,col:col+window]
        # plt.imshow(slidingW)
        # plt.show()
        io = mahotas.features.haralick(slidingW,distance=d,return_mean=True)
        #print(math.floor(window/2)+np.shape(img)[0]-1,row,col)
        HM[row,col,:]=io
        #print('\nSliding window:.............',np.shape(slidingW))
    print('Shape haralick cube',np.shape(HM))


  else:
    print('Making a int8 copy of the image')
    paddedImage[0+math.floor(window/2):np.shape(img)[0]+math.floor(window/2),0+math.floor(window/2):np.shape(img)[1]+math.floor(window/2)] = img
    paddedImage=paddedImage.astype(np.uint8)
    print('\n \t using a distance of:', d)
    for row in range(np.shape(img)[0]):
      for col in range(np.shape(img)[1]):
        #print('rrrrrrrooooooooooowwwwwwwwww........',row,'cooooooooooollllllll',col)
        slidingW = paddedImage[row:row+window,col:col+window]
        # plt.imshow(slidingW)
        # plt.show()
        io = mahotas.features.haralick(slidingW,distance=d,return_mean=True)
        #print(math.floor(window/2)+np.shape(img)[0]-1,row,col)
        HM[row,col,:]=io
        #print('\nSliding window:.............',np.shape(slidingW))
    print('Shape haralick cube',np.shape(HM))

  haralickFeatures=HM
  return haralickFeatures

def compute_gabor(image, kernels):
    feats = np.zeros((np.shape(image)[0],np.shape(image)[1],len(kernels)), dtype=np.double)
    for k, kernel in enumerate(kernels):
        filtered = ndi.convolve(image, kernel, mode='wrap')
        feats[:,:,k] = filtered
    return feats

def gaborFilter(img):
  # preparing filter bank kernels
  gabor_names = []
  kernels = []
  for theta in range(7):
      th = theta / 8.0 * np.pi
      for frequency in (0.7653,1.2755,1.7857,2.2959,2.8061):
          kernel = np.real(gabor_kernel(frequency, theta=th))
          kernels.append(kernel)
          gabor_names.append(['GaborXY_theta= pi*'+str(theta)+'/8_lambda='+str(frequency)])
  print('Number of kernels:',len(kernels))

  ima = img_as_float(img)
  gabor_feats = compute_gabor(ima, kernels)
  print('------------------------------------',np.shape(gabor_feats),gabor_names)
  return(gabor_feats,gabor_names)

#############################################################################################################



def compute_collage2d(
    image: np.ndarray,
    mask: np.ndarray,
    haralick_windows: int,
    feature_maps=False,
) -> np.ndarray:
    feats = {}
    descriptors = [
        "Collage_AngularSecondMoment",  # 0
        "Collage_Contrast",  # 1
        "Collage_Correlation",  # 2
        "Collage_SumOfSquareVariance",  # 3
        "Collage_SumAverage",  # 4
        "Collage_SumVariance",  # 5
        "Collage_SumEntropy",  # 6
        "Collage_Entropy",  # 7
        "Collage_DifferenceVariance",  # 8
        "Collage_DifferenceEntropy",  # 9
        "Collage_InformationMeasureOfCorrelation1",  # 10
        "Collage_InformationMeasureOfCorrelation2",  # 11
        "Collage_MaximalCorrelationCoefficient",  # 12
    ]

    try:
        collage = Collage(
            image,
            mask,
            svd_radius=5,
            verbose_logging=True,
            num_unique_angles=64,
            haralick_window_size=haralick_windows,
        )

        collage_feats = collage.execute()

        #print(collage_feats.shape)

        # if save_raw_path:
        #     np.save(save_raw_path, collage_feats)

        # if feature_maps:
        #     which_features = [
        #         HaralickFeature.AngularSecondMoment,
        #         HaralickFeature.Contrast,
        #         HaralickFeature.Correlation,
        #         HaralickFeature.SumOfSquareVariance,
        #         HaralickFeature.SumAverage,
        #         HaralickFeature.SumVariance,
        #         HaralickFeature.SumEntropy,
        #         HaralickFeature.Entropy,
        #         HaralickFeature.DifferenceVariance,
        #         HaralickFeature.DifferenceEntropy,
        #         HaralickFeature.InformationMeasureOfCorrelation1,
        #         HaralickFeature.InformationMeasureOfCorrelation2,
        #         HaralickFeature.MaximalCorrelationCoefficient,
        #     ]

        #     alpha = 0.5
        #     extent = 0, image.shape[1], 0, image.shape[0]

        #     for which_feature in which_features:
        #         collage_output = collage.get_single_feature_output(which_feature)

        #         figure = plt.figure(figsize=(15, 15))
        #         plt.imshow(image, cmap=plt.cm.gray, extent=extent)
        #         plt.imshow(collage_output, cmap=plt.cm.jet, alpha=alpha, extent=extent)

        #         figure.axes[0].get_xaxis().set_visible(False)
        #         figure.axes[0].get_yaxis().set_visible(False)

        #         plt.title(f"Feature map: {which_feature.name}")

        #         save_path_name = f"{save_path_feature_maps}_{which_feature.name}.png"
        #         plt.savefig(save_path_name)
        #         plt.close()

        for collage_idx, descriptor in enumerate(descriptors):
            #print(f"Processing collage {descriptor}")
            feat = collage_feats[:, :, collage_idx].flatten()
            feat = feat[~np.isnan(feat)]

            feats[f"col_des_{descriptor}"] = [
                feat.mean(),
                feat.std(),
                skew(feat),
                kurtosis(feat),
            ]

    except ValueError as err:
        print(f"VALUE ERROR- {err}")

    except Exception as err:
        print(f"EXCEPTION- {err}")

    return feats,collage_feats,descriptors

#################################################################################################################################

def _image_xor(f):
    # Turn "0" to "1" and vice versa: XOR with image consisting of "1"s
    f = f.astype(np.uint8)
    mask = np.ones(f.shape, np.uint8)
    out = np.zeros(f.shape, np.uint8)
    for i in range(f.shape[0]):
        for j in range(f.shape[1]):
            out[i,j] = f[i,j] ^ mask[i,j]
    return out



import numpy as np
from scipy import signal
import warnings

def lte_measures(f, mask=None, l=7):
    '''
    Parameters
    ----------
    f : numpy ndarray
        Image of dimensions N1 x N2.
    mask : numpy ndarray
        Mask image N1 x N2 with 1 if pixels belongs to ROI, 0 else. Give None
        if you want to consider ROI the whole image.
    l : int, optional
        Law's mask size. The default is 7.

    Returns
    -------
    features : numpy ndarray
        1)texture energy from LL kernel, 2) texture energy from EE
        kernel, 3)texture energy from SS kernel, 4)average texture
        energy from LE and EL kernels, 5)average texture energy from
        ES and SE kernels, 6)average texture energy from LS and SL
        kernels.
    labels : list
        Labels of features.
    '''

    if mask is None:
        mask = np.ones(f.shape)
        # print('----------',np.shape(mask))

    # 1) Labels
    labels = ["LTE_LL","LTE_LE","LTE_LS","LTE_EL","LTE_EE","LTE_ES","LTE_SL","LTE_SE","LTE_SS"]
    labels = [label+'_w_'+str(l) for label in labels]

    # 2) Parameters
    f = np.array(f, np.double)
    mask = np.array(mask, np.double)
    kernels = np.zeros((l,l,9), np.double)

    # 3) From 3 kernels [L, E, S], get 9 [LL, LE, LS, EL, EE, ES, SL, SE, SS]
    if l not in [3,5,7]:
        warnings.warn('Accepted vsize for Laws mask are 3, 5 and 7. Using 7 by default')
        l = 7
    if l==3:
        L = np.array([ 1,  2,  1], np.double)
        E = np.array([-1,  0,  1], np.double)
        S = np.array([-1,  2, -1], np.double)
    elif l==5:
        L = np.array([ 1,  4,  6,  4,  1], np.double)
        E = np.array([-1, -2,  0,  2,  1], np.double)
        S = np.array([-1,  0,  2,  0, -1], np.double)
    elif l==7:
        L = np.array([ 1,  6,  15,  20,  15,  6,  1], np.double)
        E = np.array([-1, -4,  -5,   0,   5,  4,  1], np.double)
        S = np.array([-1, -2,   1,   4,   1, -2, -1], np.double)

    oneskernel = np.ones((l,l), np.double)
    kernels = np.zeros((l,l,9), np.double)
    kernels[:,:,0] = np.multiply(L.reshape(-1,1),L) # LL kernel
    kernels[:,:,1] = np.multiply(L.reshape(-1,1),E) # LE kernel
    kernels[:,:,2] = np.multiply(L.reshape(-1,1),S) # LS kernel
    kernels[:,:,3] = np.multiply(E.reshape(-1,1),L) # EL kernel
    kernels[:,:,4] = np.multiply(E.reshape(-1,1),E) # EE kernel
    kernels[:,:,5] = np.multiply(E.reshape(-1,1),S) # ES kernel
    kernels[:,:,6] = np.multiply(S.reshape(-1,1),L) # SL kernel
    kernels[:,:,7] = np.multiply(S.reshape(-1,1),E) # SE kernel
    kernels[:,:,8] = np.multiply(S.reshape(-1,1),S) # SS kernel

    # 4) Get mask where convolution should be performed
    mask_c = _image_xor(mask)
    mask_conv = signal.convolve2d(mask_c, oneskernel,'valid')
    mask_conv = np.abs(np.sign(mask_conv)-1)
    # print(np.shape(mask_conv))

    # 5) Calculate energy of each convolved image with each kernel: total 9
    energy = np.zeros((np.shape(mask_conv)[0],np.shape(mask_conv)[1],9),np.double)
    area = sum(sum(mask_conv))
    for i in range(9):
        f_conv = signal.convolve2d(f, kernels[:,:,i], mode='valid')
        f_conv = np.multiply(f_conv,mask_conv)
        # print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@',np.shape(f_conv))
        energy[:,:,i] = f_conv
        # f_conv_mean = sum(sum(f_conv)) / area
        # energy[i] = np.sqrt(sum(sum(np.multiply((f_conv-f_conv_mean)**2,mask_conv)))/area)

    # 6) Calculate features
    # features = np.zeros(6,np.double)
    # features[0] = energy[0]
    # features[1] = energy[4]
    # features[2] = energy[8]
    # features[3] = (energy[1]+energy[3])/2
    # features[4] = (energy[5]+energy[7])/2
    # features[5] = (energy[2]+energy[6])/2

    return energy, labels

##############################################################################################

def extract2DFeatureInfo(img_org,mask_org,ws_options=[3,5,7,9,11],class_options = ['raw','gray','gradient','haralick','gabor','laws','collage'], with_stats=True):

  #class_options = (OPTIONAL) cell array of strings corresponding to desired feature classes:
  #                 DEFAULT: class_options = {'raw','gray','gradient','haralick','gabor','laws','collage'}; ### still unused
  #ws_options = (OPTIONAL) array of integers corresponding to desired window levels:
  #                 DEFAULT: ws_options = [3, 5, 7, 9, 11]


  #Initialization
  matrixNames = []
  matrixNames = pd.DataFrame(matrixNames)
  matrixFeatures = []
  matrixFeatures = pd.DataFrame(matrixFeatures)
  statFeatures = []
  statFeatures = pd.DataFrame(statFeatures)
  statFeatureNames =[]
  statFeatures = pd.DataFrame(statFeatureNames)

  ##RECOMMENDED: CROP IMAGE AND MASK (saves time and memory)!
  [img,mask] = boundingbox2(img_org,mask_org,np.max(ws_options))
  # plt.imshow(mask)
  # plt.show()
  print('Cropped Image shape:',np.shape(img))

  if len(np.shape(img)) > 2: # Checking wheter the image is a volume
    if len(np.shape(mask)) < 3: # Checking if there is a mask for each slice of the volume
      for i in range(np.shape(img)[2]): # loop through all slices of the volumen

        ##2D Feature Intensity Extraction
        print('Extracting Features for provide image slices and a single mask')

        #------------- Raw intensity features ----------------
        feat_vect = extract2DFeatIntensities(img[:,:,i], mask)


        #--------------Gray Level Statistics----------------%
        print('\nExtracting Gray Level Statistics:\n')
        grayFeats = []
        grayFeats = pd.DataFrame(grayFeats)
        for ws in ws_options:
          print('\t Using a window size of ',ws,'\n')
          gf = grayfilts2(img[:,:,i],ws)
          # print('Gray result:',np.shape(gf))
          gf = grayfilts2(img[:,:,i],ws)
          # print('Gray result:',np.shape(gf))
          feat_vect = extract2DFeatIntensities(gf, mask)
          # print('Feature vector shape:',np.shape(feat_vect))

    else:
      ##2D Feature Intensity Extraction
      print('Extracting Features for provide image slices and maks')

      #------------- Raw intensity features with multiple masks ----------------
      feat_vect = extract2DFeatIntensities(img[:,:,i], mask[:,:,i])
      # print('Feature vector shape:',np.shape(feat_vect))
      #print(feat_vect[0:100])


      #--------------Gray Level Statistics----------------%
      print('\nExtracting Gray Level Statistics:\n')
      grayFeats = []
      grayFeats = pd.DataFrame(grayFeats)
      for ws in ws_options:
        print('\n \t Using a window size of ',ws,'\n')
        gf = grayfilts2(img[:,:,i],ws)
        # print('Gray result:',np.shape(gf))
        feat_vect = extract2DFeatIntensities(gf, mask)
        # print('Feature vector shape:',np.shape(feat_vect))

  else:

    ##2D Feature Intensity Extraction
    print('\t Extracting intensity Features for provide single image slice:\n')

    #------------- Raw intensity features ----------------
    print('Raw intensities')
    feat_vect = extract2DFeatIntensities(img, mask)
    print('Raw intensity Feature vector shape:..............\n',np.shape(feat_vect))
    print(feat_vect)

    if with_stats == True:
      statFeatures = pd.concat([statFeatures,pd.DataFrame([feat_vect.mean(),feat_vect.std(),skew(feat_vect),kurtosis(feat_vect)])],axis = 1)
      statistics = ['Mean_of_','std_of_','skew_of_','kurtosis_of_']



    matrixFeatures = pd.concat([matrixFeatures,pd.DataFrame(feat_vect)], axis = 0)
    matrixNames = pd.concat([matrixNames,pd.DataFrame(['Raw intensity'])])
    # statFeatureNames = pd.concat([pd.DataFrame(statFeatureNames),pd.DataFrame(['Mean Raw','std Raw','skew Raw','Kurtosis Raw'])])
    print('xxxxxxxxxxxxxxxx',np.shape(matrixFeatures),np.shape(statFeatures))


    #--------------Gray Level Statistics----------------%
    print('\n \t Extracting Gray Level Statistics:\n')


    for ws in ws_options:

      print('\n \t Using a window size of ',ws,'\n')
      gf = grayfilts2(img,ws)
      feat_names = ['Mean Image_','Median Image_','std Image_','Windowed range image_']
      feat_vect = extract2DFeatIntensities(gf, mask)
      print('Gray level Feature vector statistics:...............\n',np.shape(feat_vect))
      f_names = [x+'_w'+str(ws) for x in feat_names]
      matrixFeatures = pd.concat([matrixFeatures,pd.DataFrame(feat_vect)], axis=1)
      matrixNames = pd.concat([matrixNames,pd.DataFrame(f_names)],axis = 0)


      if with_stats == True:
        for f_idx in range(feat_vect.shape[1]):
          statFeatures = pd.concat([statFeatures,pd.DataFrame([feat_vect.iloc[:,f_idx].mean(),
                                                               feat_vect.iloc[:,f_idx].std(),
                                                               skew(feat_vect.iloc[:,f_idx]),
                                                               kurtosis(feat_vect.iloc[:,f_idx])])], axis = 0)

      print('xxxxxxxxxxxxxxxx',np.shape(matrixFeatures),np.shape(matrixNames),np.shape(statFeatures))
      print(matrixNames,'\n',statFeatureNames)

      # ------------------ Haralick features ------------------------------
      print('\nExtracting Haralick-based (GLCM) features:\n')
      haralick_labels = ["Haralick Angular Second Moment",
                   "Haralick Contrast",
                   "Haralick Correlation",
                   "Haralick Sum of Squares: Variance",
                   "Haralick Inverse Difference Moment",
                   "Haralick Sum Average",
                   "Haralick Sum Variance",
                   "Haralick Sum Entropy",
                   "Haralick Entropy",
                   "Haralick Difference Variance",
                   "Haralick Difference Entropy",
                   "Haralick Information Measure of Correlation 1",
                   "Haralick Information Measure of Correlation 2"]
      HaralickFeat = extractHaralick(img,ws)
      feat_vect = extract2DFeatIntensities(HaralickFeat, mask)
      #print('Haralick feature vector statistics:.................\n',np.shape(feat_vect))
      f_names = [x+'_w'+str(ws) for x in haralick_labels]
      matrixFeatures = pd.concat([matrixFeatures,pd.DataFrame(feat_vect)], axis=1)
      matrixNames = pd.concat([matrixNames,pd.DataFrame(f_names)],axis = 0)
      if with_stats == True:
        for f_idx in range(feat_vect.shape[1]):
          statFeatures = pd.concat([statFeatures,pd.DataFrame([feat_vect.iloc[:,f_idx].mean(),
                                                               feat_vect.iloc[:,f_idx].std(),
                                                               skew(feat_vect.iloc[:,f_idx]),
                                                               kurtosis(feat_vect.iloc[:,f_idx])])])

      print('xxxxxxxxxxxxxxxx',np.shape(matrixFeatures),np.shape(statFeatures),'\n',matrixNames[1:6])



      #---------------- Laws--------------------------------------
      print('\nExtracting Laws features:\n')
      Laws_out = lte_measures(img_org, l=ws)
      print('+++++++++++++++++++++++++++++++++++++++++++\n',np.shape(Laws_out[0]))
      feat_vect = extract2DFeatIntensities(Laws_out[0], mask_org[1:-1,1:-1])
      f_names = Laws_out[1]
      matrixFeatures = pd.concat([matrixFeatures,pd.DataFrame(feat_vect)], axis=1)
      matrixNames = pd.concat([matrixNames,pd.DataFrame(f_names)],axis = 0)

      if with_stats == True:
        for f_idx in range(feat_vect.shape[1]):
          statFeatures = pd.concat([statFeatures,pd.DataFrame([feat_vect.iloc[:,f_idx].mean(),
                                                               feat_vect.iloc[:,f_idx].std(),
                                                               skew(feat_vect.iloc[:,f_idx]),
                                                               kurtosis(feat_vect.iloc[:,f_idx])])], axis = 0)
      print('xxxxxxxxxxxxxxxx',np.shape(matrixFeatures), statFeatures.shape, '\n',matrixNames[3:7])


      # ---------------- Collage ------------------------------------------
      print('\nExtracting Collage features:\n')
      # due to limitation in the minumum patch size of collage pack use "img_org" instead of the cropped version "img"
      mask_complete = np.ones(np.shape(img_org)) # a fake mask is used to evaluate the whole image
      coll = compute_collage2d(img_org,mask_complete, haralick_windows=ws)
      feat_vect = extract2DFeatIntensities(coll[1], mask_org)
      print(coll[2])
      f_names = [x+'_w'+str(ws) for x in coll[2]]
      matrixFeatures = pd.concat([matrixFeatures,pd.DataFrame(feat_vect)], axis=1)
      matrixNames = pd.concat([matrixNames,pd.DataFrame(f_names)],axis = 0)

      if with_stats == True:
        for f_idx in range(feat_vect.shape[1]):
          statFeatures = pd.concat([statFeatures,pd.DataFrame([feat_vect.iloc[:,f_idx].mean(),
                                                               feat_vect.iloc[:,f_idx].std(),
                                                               skew(feat_vect.iloc[:,f_idx]),
                                                               kurtosis(feat_vect.iloc[:,f_idx])])], axis = 0)
      print('xxxxxxxxxxxxxxxx',np.shape(matrixFeatures),'\n',matrixFeatures,'\n',statFeatures.shape)


      #------------- Gradient ------------------------------
      print('\nExtracting Gradient features:\n')
      feat_names = ['Gradient sobelx','Gradient sobely','Gradient sobelxy','Gradient sobelyx','Gradient x','Gradient y','Gradient magnitude','Gradient dx','Gradient dy','Gradient diagonal']
      gradOut = gradfilts2(img)
      # print('Grad results:\n',gradOut)
      f_names = [x+'_w'+str(ws) for x in feat_names]
      feat_vect = extract2DFeatIntensities(gradOut, mask)
      # print('Gray level statistics:\n',np.shape(feat_vect),feat_vect[0:100])
      matrixFeatures = pd.concat([matrixFeatures,pd.DataFrame(feat_vect)], axis=1)
      matrixNames = pd.concat([matrixNames,pd.DataFrame(f_names)],axis = 0)

      if with_stats == True:
        for f_idx in range(feat_vect.shape[1]):
          statFeatures = pd.concat([statFeatures,pd.DataFrame([feat_vect.iloc[:,f_idx].mean(),
                                                               feat_vect.iloc[:,f_idx].std(),
                                                               skew(feat_vect.iloc[:,f_idx]),
                                                               kurtosis(feat_vect.iloc[:,f_idx])])], axis = 0)
      print('xxxxxxxxxxxxxxxx',np.shape(matrixFeatures), np.shape(statFeatures))



    #---------------- Gabor -------------------------------------------
    print('\n Extracting Gabor features')
    gabor_matrix = gaborFilter(img)
    feat_vect = extract2DFeatIntensities(gabor_matrix[0], mask)
    matrixFeatures = pd.concat([matrixFeatures,pd.DataFrame(feat_vect)], axis=1)
    matrixNames = pd.concat([matrixNames,pd.DataFrame(gabor_matrix[1])],axis = 0)

    if with_stats == True:
      for f_idx in range(feat_vect.shape[1]):
        statFeatures = pd.concat([statFeatures,pd.DataFrame([feat_vect.iloc[:,f_idx].mean(),
                                                              feat_vect.iloc[:,f_idx].std(),
                                                              skew(feat_vect.iloc[:,f_idx]),
                                                              kurtosis(feat_vect.iloc[:,f_idx])])], axis = 0)
    print('xxxxxxxxxxxxxxxx',np.shape(matrixFeatures),np.shape(statFeatures))

    print(np.shape(matrixNames))
    print(matrixNames)

    for name in matrixNames.iloc[:,0]:
      # print('--------->',name,[r+name for r in statistics])
      statFeatureNames = pd.concat([pd.DataFrame(statFeatureNames),pd.DataFrame([r+name for r in statistics])])

    return (matrixNames,matrixFeatures,statFeatures,statFeatureNames)



